{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ~ Objective : Scapping Top Repositories for Topics on GitHub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the steps we'll follow:\n",
    "\n",
    "- We're going to scrape https://github.com/topics\n",
    "- We'll get a list of topics. For each topic, we'll get topic title, topic page URL and topic description\n",
    "- For each topic, we'll get the top 25 repositories in the topic from the topic page\n",
    "- For each repository, we'll grab the repo name, username, stars and repo URL\n",
    "- For each topic we'll create a CSV file in the following format:\n",
    "    - Repo Name,Username,Stars,Repo URL\n",
    "    - three.js,mrdoob,69700,https://github.com/mrdoob/three.js\n",
    "    - libgdx,libgdx,18300,https://github.com/libgdx/libgdx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ~ Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessory modules\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the list of topics from Github\n",
    "- Explain how you'll do it.\n",
    "\n",
    "- use requests to downlaod the page\n",
    "- user BS4 to parse and extract information\n",
    "- convert to a Pandas dataframe\n",
    "\n",
    "Let's write a function to download the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will fetch trending topics from github\n",
    "# Function returns pandas dataframe\n",
    "\n",
    "def fetch_topics_detail(topics_soup):\n",
    "    # fetching topic name\n",
    "    topic_name_class = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
    "    topic_name = topics_soup.find_all('p',{'class':topic_name_class})\n",
    "    topic_titles = []\n",
    "    for i in topic_name:\n",
    "        topic_titles.append(i.text)\n",
    "\n",
    "    # fetching topic Descirption\n",
    "    topic_name_disc_class = 'f5 color-text-secondary mb-0 mt-1'\n",
    "    topic_name_disc = topics_soup.find_all('p',{'class':topic_name_disc_class})\n",
    "    topic_disc = []\n",
    "    for i in topic_name_disc:\n",
    "        topic_disc.append(i.text.strip())\n",
    "\n",
    "    # fetching topic link\n",
    "    topic_name_link = topics_soup.find_all('a',{'class':'d-flex no-underline'})\n",
    "    topic_link = []\n",
    "    for i in topic_name_link:\n",
    "        topic_link.append(base_link+i['href'])\n",
    "    \n",
    "    # returning details in panda's dataframe\n",
    "    return pd.DataFrame({'t_name':topic_titles, 't_desc': topic_disc, 't_link':topic_link})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the top repositories from a topic page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will fetch repository details.\n",
    "\n",
    "def fetch_repo_details(lin):\n",
    "# defining necessory variables\n",
    "    user_name = []\n",
    "    repo_name = []\n",
    "    repo_link = []\n",
    "    star = []\n",
    "    repo_selection_class = 'f3 color-text-secondary text-normal lh-condensed'\n",
    "    star_class = 'social-count float-none'\n",
    "\n",
    "\n",
    "    resp = requests.get(lin)\n",
    "    \n",
    "    if resp.status_code != 200:\n",
    "#         raise Exception('Failed to load page {}'.format(lin))\n",
    "        return\n",
    "    raw_topic = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    \n",
    "# code to fetch repo_username, repo_name, repo_link\n",
    "    repo_details = raw_topic.find_all('h1', {'class':repo_selection_class})\n",
    "    for i in repo_details:\n",
    "        user_name.append(i.find_all('a')[0].text.strip())\n",
    "        repo_link.append(base_link+i.find_all('a')[0]['href'])\n",
    "        repo_name.append(i.find_all('a')[1].text.strip())\n",
    "\n",
    "# code to fetch stars of repo\n",
    "    star_count = raw_topic.find_all('a', {'class':star_class})\n",
    "    for i in star_count:\n",
    "        if i.text.strip()[-1] == 'k':\n",
    "            star.append(int(float(i.text.strip()[:-1]))*1000)\n",
    "        else:\n",
    "            star.append(int(i.text.strip()))\n",
    "            \n",
    "# creating dictionary to store the data & returning as pandas dataframe       \n",
    "    final_dict = {'repo user': user_name,\n",
    "             'repo title': repo_name,\n",
    "             'repo stars': star,\n",
    "             'repo link': repo_link}\n",
    "\n",
    "    return pd.DataFrame(final_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "- We have a funciton to get the list of topics.\n",
    "- We have a function to get data of repos from a topics page.\n",
    "- Let's create a function to put them together & create and save as csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(t_df):\n",
    "\n",
    "# Checking for folder 'data'. If it doesn't exists then create one.\n",
    "\n",
    "    if os.path.exists('data'):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir('data')\n",
    "\n",
    "# move to directory: 'data'\n",
    "    os.chdir('data')    \n",
    "    \n",
    "# iterate over dataframe passed as parameter.\n",
    "    for index, row in t_df.iterrows():\n",
    "        topic_name = row[0]\n",
    "        topic_link = row[2]\n",
    "\n",
    "        csv_name = topic_name+'.csv'\n",
    "        repo_df = fetch_repo_details(topic_link)\n",
    "        repo_df.to_csv(csv_name, index=None)\n",
    "        print('csv created for {}'.format(topic_name))        \n",
    "#         if os.path.exists(csv_name):\n",
    "#             print('The file {} already exists. Skipping...'.format(csv_name))\n",
    "#             pass\n",
    "#         else:\n",
    "#             repo_df = fetch_repo_details(topic_link)\n",
    "#             if type(repo_df) != None:\n",
    "#                 repo_df.to_csv(csv_name, index=None)\n",
    "#                 print('csv created for {}'.format(topic_name))\n",
    "#             else:\n",
    "#                 pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv created for 3D\n",
      "csv created for Ajax\n",
      "csv created for Algorithm\n",
      "csv created for Amp\n",
      "csv created for Android\n",
      "csv created for Angular\n",
      "csv created for Ansible\n",
      "csv created for API\n",
      "csv created for Arduino\n",
      "csv created for ASP.NET\n",
      "csv created for Atom\n",
      "csv created for Awesome Lists\n",
      "csv created for Amazon Web Services\n",
      "csv created for Azure\n",
      "csv created for Babel\n",
      "csv created for Bash\n",
      "csv created for Bitcoin\n",
      "csv created for Bootstrap\n",
      "csv created for Bot\n",
      "csv created for C\n",
      "csv created for Chrome\n",
      "csv created for Chrome extension\n",
      "csv created for Command line interface\n",
      "csv created for Clojure\n",
      "csv created for Code quality\n",
      "csv created for Code review\n",
      "csv created for Compiler\n",
      "csv created for Continuous integration\n",
      "csv created for COVID-19\n",
      "csv created for C++\n"
     ]
    }
   ],
   "source": [
    "base_link = 'https://github.com'\n",
    "\n",
    "topics_result = requests.get(\"https://github.com/topics\")\n",
    "topics_soup = BeautifulSoup(topics_result.text, \"html.parser\")\n",
    "create_csv(fetch_topics_detail(topics_soup))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
